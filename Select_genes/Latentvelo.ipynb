{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning, folder already exists. This may overwrite a previous fit.\n",
      "2000 velocity genes used\n",
      "epoch 0, full loss 342.208, val loss 264.259, recon MSE 5.277, traj MSE 2.452, reg loss -2.041\n",
      "epoch 1, full loss 255.098, val loss 201.874, recon MSE 1.817, traj MSE 1.509, reg loss -2.330\n",
      "epoch 2, full loss 208.012, val loss 173.425, recon MSE 2.008, traj MSE 1.149, reg loss -2.495\n",
      "epoch 3, full loss 181.666, val loss 146.723, recon MSE 1.656, traj MSE 1.070, reg loss -2.558\n",
      "epoch 4, full loss 146.250, val loss 119.723, recon MSE 1.838, traj MSE 1.045, reg loss -2.661\n",
      "epoch 5, full loss 116.983, val loss 93.207, recon MSE 1.686, traj MSE 1.036, reg loss -2.720\n",
      "epoch 6, full loss 85.141, val loss 66.199, recon MSE 1.613, traj MSE 1.032, reg loss -2.815\n",
      "epoch 7, full loss 54.482, val loss 39.294, recon MSE 1.398, traj MSE 1.030, reg loss -2.887\n",
      "epoch 8, full loss 23.737, val loss 10.555, recon MSE 1.219, traj MSE 1.030, reg loss -2.060\n",
      "epoch 9, full loss -6.799, val loss -18.408, recon MSE 1.073, traj MSE 1.012, reg loss -1.879\n",
      "epoch 10, full loss -38.179, val loss -46.834, recon MSE 0.892, traj MSE 0.854, reg loss -1.479\n",
      "epoch 11, full loss -69.391, val loss -76.122, recon MSE 0.861, traj MSE 0.661, reg loss -0.761\n",
      "epoch 12, full loss -102.030, val loss -106.326, recon MSE 0.785, traj MSE 0.603, reg loss -0.790\n",
      "epoch 13, full loss -132.749, val loss -135.555, recon MSE 0.694, traj MSE 0.585, reg loss -0.409\n",
      "epoch 14, full loss -163.683, val loss -164.605, recon MSE 0.623, traj MSE 0.579, reg loss -0.263\n",
      "epoch 15, full loss -194.148, val loss -193.755, recon MSE 0.535, traj MSE 0.548, reg loss 0.008\n",
      "epoch 16, full loss -225.661, val loss -223.294, recon MSE 0.506, traj MSE 0.447, reg loss -0.738\n",
      "epoch 17, full loss -254.849, val loss -251.466, recon MSE 0.536, traj MSE 0.414, reg loss -0.643\n",
      "epoch 18, full loss -285.927, val loss -280.650, recon MSE 0.460, traj MSE 0.401, reg loss -0.320\n",
      "epoch 19, full loss -316.479, val loss -308.712, recon MSE 0.450, traj MSE 0.393, reg loss -0.807\n",
      "epoch 20, full loss -345.945, val loss -336.960, recon MSE 0.420, traj MSE 0.381, reg loss -0.683\n",
      "epoch 21, full loss -371.234, val loss -363.763, recon MSE 0.424, traj MSE 0.414, reg loss -0.069\n",
      "epoch 22, full loss -400.339, val loss -387.158, recon MSE 0.404, traj MSE 0.355, reg loss -0.228\n",
      "epoch 23, full loss -428.446, val loss -415.871, recon MSE 0.366, traj MSE 0.355, reg loss 0.127\n",
      "epoch 24, full loss -455.670, val loss -439.476, recon MSE 0.350, traj MSE 0.331, reg loss 0.187\n",
      "epoch 25, full loss -480.685, val loss -463.152, recon MSE 0.361, traj MSE 0.305, reg loss 0.042\n",
      "epoch 26, full loss -505.336, val loss -488.413, recon MSE 0.341, traj MSE 0.305, reg loss 0.493\n",
      "epoch 27, full loss -522.705, val loss -508.592, recon MSE 0.339, traj MSE 0.330, reg loss 0.024\n",
      "epoch 28, full loss -545.035, val loss -531.700, recon MSE 0.350, traj MSE 0.301, reg loss 0.015\n",
      "epoch 29, full loss -566.203, val loss -550.131, recon MSE 0.319, traj MSE 0.295, reg loss 0.465\n",
      "epoch 30, full loss -588.501, val loss -572.407, recon MSE 0.296, traj MSE 0.279, reg loss 0.068\n",
      "epoch 31, full loss -602.727, val loss -587.345, recon MSE 0.302, traj MSE 0.285, reg loss 0.269\n",
      "epoch 32, full loss -614.105, val loss -604.406, recon MSE 0.294, traj MSE 0.302, reg loss 0.150\n",
      "epoch 33, full loss -631.257, val loss -611.046, recon MSE 0.290, traj MSE 0.274, reg loss 0.206\n",
      "epoch 34, full loss -649.817, val loss -632.853, recon MSE 0.265, traj MSE 0.255, reg loss -0.030\n",
      "epoch 35, full loss -661.755, val loss -646.800, recon MSE 0.257, traj MSE 0.252, reg loss 0.175\n",
      "epoch 36, full loss -664.125, val loss -658.593, recon MSE 0.260, traj MSE 0.277, reg loss 0.199\n",
      "epoch 37, full loss -681.244, val loss -663.264, recon MSE 0.246, traj MSE 0.249, reg loss 0.306\n",
      "epoch 38, full loss -687.398, val loss -675.023, recon MSE 0.247, traj MSE 0.242, reg loss 0.152\n",
      "epoch 39, full loss -687.405, val loss -682.661, recon MSE 0.255, traj MSE 0.253, reg loss 0.249\n",
      "epoch 40, full loss -689.361, val loss -679.143, recon MSE 0.250, traj MSE 0.255, reg loss 0.041\n",
      "epoch 41, full loss -701.842, val loss -686.213, recon MSE 0.230, traj MSE 0.238, reg loss 0.170\n",
      "epoch 42, full loss -706.934, val loss -693.510, recon MSE 0.230, traj MSE 0.232, reg loss -0.001\n",
      "epoch 43, full loss -711.872, val loss -701.539, recon MSE 0.222, traj MSE 0.236, reg loss 0.188\n",
      "epoch 44, full loss -714.144, val loss -703.366, recon MSE 0.219, traj MSE 0.234, reg loss 0.196\n",
      "epoch 45, full loss -720.710, val loss -705.977, recon MSE 0.212, traj MSE 0.222, reg loss 0.146\n",
      "epoch 46, full loss -725.303, val loss -712.445, recon MSE 0.208, traj MSE 0.220, reg loss 0.142\n",
      "epoch 47, full loss -725.880, val loss -715.591, recon MSE 0.211, traj MSE 0.219, reg loss 0.120\n",
      "epoch 48, full loss -724.316, val loss -715.455, recon MSE 0.209, traj MSE 0.228, reg loss 0.063\n",
      "epoch 49, full loss -722.091, val loss -715.051, recon MSE 0.205, traj MSE 0.232, reg loss -0.095\n",
      "Loading best model at 46 epochs.\n"
     ]
    }
   ],
   "source": [
    "import latentvelo as ltv\n",
    "import numpy as np\n",
    "import scanpy as sc\n",
    "import scvelo as scv\n",
    "import pandas as pd\n",
    "import gc\n",
    "import time\n",
    "np.random.seed(2024)\n",
    "\n",
    "adata = scv.read(\"/home/liyr/hpz/real_data_graph/Forebrain/LatentVelo.h5ad\")\n",
    "\n",
    "adata.var['velocity_genes'] = True\n",
    "adata.obs['clusters'] = pd.Categorical(adata.obs['clusters'],categories=['Radial Glia', 'Neuroblast','Immature Neuron', 'Neuron'], ordered=True)\n",
    "#adata.obs['exp_time'] = np.array(adata.obs['clusters'].cat.codes)\n",
    "#adata.obs['exp_time'] = adata.obs['exp_time']/adata.obs['exp_time'].max()\n",
    "\n",
    "\n",
    "spliced_key = 'spliced'\n",
    "unspliced_key = 'unspliced'\n",
    "\n",
    "spliced_library_sizes = adata.layers[spliced_key].sum(1)\n",
    "unspliced_library_sizes = adata.layers[unspliced_key].sum(1)\n",
    "\n",
    "if len(spliced_library_sizes.shape) == 1: \n",
    "    spliced_library_sizes = spliced_library_sizes[:,None]\n",
    "if len(unspliced_library_sizes.shape) == 1: \n",
    "    unspliced_library_sizes = unspliced_library_sizes[:,None]\n",
    "\n",
    "adata.obs['spliced_size_factor'] = spliced_library_sizes #spliced_all_size_factors\n",
    "adata.obs['unspliced_size_factor'] = unspliced_library_sizes #unspliced_all_size_factors\n",
    "\n",
    "model = ltv.models.VAE(observed = adata.n_vars) # observed: number of genes\n",
    "epochs, val_ae, val_traj = ltv.train(model, adata,name='simulation_mono')\n",
    "        \n",
    "latent_adata, adata = ltv.output_results(model, adata, gene_velocity=True)\n",
    "z_traj, times = ltv.cell_trajectories(model, adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.layers['velocity'] = adata.layers['velo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CDK11B</th>\n",
       "      <th>LINC00982</th>\n",
       "      <th>CEP104</th>\n",
       "      <th>RERE</th>\n",
       "      <th>ENO1</th>\n",
       "      <th>LZIC</th>\n",
       "      <th>MTOR</th>\n",
       "      <th>DHRS3</th>\n",
       "      <th>ATP13A2</th>\n",
       "      <th>RCC2</th>\n",
       "      <th>...</th>\n",
       "      <th>WDR44</th>\n",
       "      <th>GRIA3</th>\n",
       "      <th>RAB33A</th>\n",
       "      <th>LINC00632</th>\n",
       "      <th>AFF2</th>\n",
       "      <th>HMGB3</th>\n",
       "      <th>GDI1</th>\n",
       "      <th>PCDH11Y</th>\n",
       "      <th>DDX3Y</th>\n",
       "      <th>clusters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.016512</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.028449</td>\n",
       "      <td>0.090379</td>\n",
       "      <td>0.186424</td>\n",
       "      <td>0.027977</td>\n",
       "      <td>0.027892</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.130918</td>\n",
       "      <td>0.020485</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025961</td>\n",
       "      <td>0.074761</td>\n",
       "      <td>0.112933</td>\n",
       "      <td>0.005152</td>\n",
       "      <td>0.013255</td>\n",
       "      <td>0.166676</td>\n",
       "      <td>0.412796</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.026657</td>\n",
       "      <td>Immature Neuron</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.016512</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.028449</td>\n",
       "      <td>0.090379</td>\n",
       "      <td>0.186424</td>\n",
       "      <td>0.027977</td>\n",
       "      <td>0.027892</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.130918</td>\n",
       "      <td>0.020485</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025961</td>\n",
       "      <td>0.074761</td>\n",
       "      <td>0.112933</td>\n",
       "      <td>0.005152</td>\n",
       "      <td>0.013255</td>\n",
       "      <td>0.166676</td>\n",
       "      <td>0.412796</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.026657</td>\n",
       "      <td>Immature Neuron</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.026353</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.040429</td>\n",
       "      <td>0.147367</td>\n",
       "      <td>0.166600</td>\n",
       "      <td>0.058250</td>\n",
       "      <td>0.030922</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.092936</td>\n",
       "      <td>0.011462</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024960</td>\n",
       "      <td>0.102460</td>\n",
       "      <td>0.167599</td>\n",
       "      <td>0.004626</td>\n",
       "      <td>0.005686</td>\n",
       "      <td>0.179902</td>\n",
       "      <td>0.344754</td>\n",
       "      <td>0.003223</td>\n",
       "      <td>0.032272</td>\n",
       "      <td>Immature Neuron</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.026353</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.040429</td>\n",
       "      <td>0.147367</td>\n",
       "      <td>0.166600</td>\n",
       "      <td>0.058250</td>\n",
       "      <td>0.030922</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.092936</td>\n",
       "      <td>0.011462</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024960</td>\n",
       "      <td>0.102460</td>\n",
       "      <td>0.167599</td>\n",
       "      <td>0.004626</td>\n",
       "      <td>0.005686</td>\n",
       "      <td>0.179902</td>\n",
       "      <td>0.344754</td>\n",
       "      <td>0.003223</td>\n",
       "      <td>0.032272</td>\n",
       "      <td>Immature Neuron</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.038448</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.028653</td>\n",
       "      <td>0.105894</td>\n",
       "      <td>0.187071</td>\n",
       "      <td>0.093507</td>\n",
       "      <td>0.015828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.080902</td>\n",
       "      <td>0.025393</td>\n",
       "      <td>...</td>\n",
       "      <td>0.031350</td>\n",
       "      <td>0.110897</td>\n",
       "      <td>0.186254</td>\n",
       "      <td>0.009699</td>\n",
       "      <td>0.008310</td>\n",
       "      <td>0.142592</td>\n",
       "      <td>0.331819</td>\n",
       "      <td>0.006758</td>\n",
       "      <td>0.047084</td>\n",
       "      <td>Immature Neuron</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16099</th>\n",
       "      <td>0.026258</td>\n",
       "      <td>0.004295</td>\n",
       "      <td>0.042906</td>\n",
       "      <td>0.157160</td>\n",
       "      <td>0.452454</td>\n",
       "      <td>0.085320</td>\n",
       "      <td>0.012349</td>\n",
       "      <td>0.069111</td>\n",
       "      <td>0.041184</td>\n",
       "      <td>0.040413</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012109</td>\n",
       "      <td>0.018822</td>\n",
       "      <td>0.022021</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.231765</td>\n",
       "      <td>0.131174</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.068234</td>\n",
       "      <td>Radial Glia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16100</th>\n",
       "      <td>0.019938</td>\n",
       "      <td>0.005847</td>\n",
       "      <td>0.016291</td>\n",
       "      <td>0.086376</td>\n",
       "      <td>0.577310</td>\n",
       "      <td>0.048018</td>\n",
       "      <td>0.017231</td>\n",
       "      <td>0.125206</td>\n",
       "      <td>0.032764</td>\n",
       "      <td>0.073434</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.017502</td>\n",
       "      <td>0.021853</td>\n",
       "      <td>0.009320</td>\n",
       "      <td>0.212488</td>\n",
       "      <td>0.087141</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015771</td>\n",
       "      <td>Radial Glia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16101</th>\n",
       "      <td>0.019938</td>\n",
       "      <td>0.005847</td>\n",
       "      <td>0.016291</td>\n",
       "      <td>0.086376</td>\n",
       "      <td>0.577310</td>\n",
       "      <td>0.048018</td>\n",
       "      <td>0.017231</td>\n",
       "      <td>0.125206</td>\n",
       "      <td>0.032764</td>\n",
       "      <td>0.073434</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.017502</td>\n",
       "      <td>0.021853</td>\n",
       "      <td>0.009320</td>\n",
       "      <td>0.212488</td>\n",
       "      <td>0.087141</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015771</td>\n",
       "      <td>Radial Glia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16102</th>\n",
       "      <td>0.019938</td>\n",
       "      <td>0.005847</td>\n",
       "      <td>0.016291</td>\n",
       "      <td>0.086376</td>\n",
       "      <td>0.577310</td>\n",
       "      <td>0.048018</td>\n",
       "      <td>0.017231</td>\n",
       "      <td>0.125206</td>\n",
       "      <td>0.032764</td>\n",
       "      <td>0.073434</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.017502</td>\n",
       "      <td>0.021853</td>\n",
       "      <td>0.009320</td>\n",
       "      <td>0.212488</td>\n",
       "      <td>0.087141</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015771</td>\n",
       "      <td>Radial Glia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16103</th>\n",
       "      <td>0.019938</td>\n",
       "      <td>0.005847</td>\n",
       "      <td>0.016291</td>\n",
       "      <td>0.086376</td>\n",
       "      <td>0.577310</td>\n",
       "      <td>0.048018</td>\n",
       "      <td>0.017231</td>\n",
       "      <td>0.125206</td>\n",
       "      <td>0.032764</td>\n",
       "      <td>0.073434</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.017502</td>\n",
       "      <td>0.021853</td>\n",
       "      <td>0.009320</td>\n",
       "      <td>0.212488</td>\n",
       "      <td>0.087141</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015771</td>\n",
       "      <td>Radial Glia</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32147 rows Ã— 2001 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         CDK11B  LINC00982    CEP104      RERE      ENO1      LZIC      MTOR  \\\n",
       "0      0.016512   0.000000  0.028449  0.090379  0.186424  0.027977  0.027892   \n",
       "1      0.016512   0.000000  0.028449  0.090379  0.186424  0.027977  0.027892   \n",
       "2      0.026353   0.000000  0.040429  0.147367  0.166600  0.058250  0.030922   \n",
       "3      0.026353   0.000000  0.040429  0.147367  0.166600  0.058250  0.030922   \n",
       "4      0.038448   0.000000  0.028653  0.105894  0.187071  0.093507  0.015828   \n",
       "...         ...        ...       ...       ...       ...       ...       ...   \n",
       "16099  0.026258   0.004295  0.042906  0.157160  0.452454  0.085320  0.012349   \n",
       "16100  0.019938   0.005847  0.016291  0.086376  0.577310  0.048018  0.017231   \n",
       "16101  0.019938   0.005847  0.016291  0.086376  0.577310  0.048018  0.017231   \n",
       "16102  0.019938   0.005847  0.016291  0.086376  0.577310  0.048018  0.017231   \n",
       "16103  0.019938   0.005847  0.016291  0.086376  0.577310  0.048018  0.017231   \n",
       "\n",
       "          DHRS3   ATP13A2      RCC2  ...     WDR44     GRIA3    RAB33A  \\\n",
       "0      0.000000  0.130918  0.020485  ...  0.025961  0.074761  0.112933   \n",
       "1      0.000000  0.130918  0.020485  ...  0.025961  0.074761  0.112933   \n",
       "2      0.000000  0.092936  0.011462  ...  0.024960  0.102460  0.167599   \n",
       "3      0.000000  0.092936  0.011462  ...  0.024960  0.102460  0.167599   \n",
       "4      0.000000  0.080902  0.025393  ...  0.031350  0.110897  0.186254   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "16099  0.069111  0.041184  0.040413  ...  0.000000  0.012109  0.018822   \n",
       "16100  0.125206  0.032764  0.073434  ...  0.000000  0.000000  0.017502   \n",
       "16101  0.125206  0.032764  0.073434  ...  0.000000  0.000000  0.017502   \n",
       "16102  0.125206  0.032764  0.073434  ...  0.000000  0.000000  0.017502   \n",
       "16103  0.125206  0.032764  0.073434  ...  0.000000  0.000000  0.017502   \n",
       "\n",
       "       LINC00632      AFF2     HMGB3      GDI1   PCDH11Y     DDX3Y  \\\n",
       "0       0.005152  0.013255  0.166676  0.412796  0.000000  0.026657   \n",
       "1       0.005152  0.013255  0.166676  0.412796  0.000000  0.026657   \n",
       "2       0.004626  0.005686  0.179902  0.344754  0.003223  0.032272   \n",
       "3       0.004626  0.005686  0.179902  0.344754  0.003223  0.032272   \n",
       "4       0.009699  0.008310  0.142592  0.331819  0.006758  0.047084   \n",
       "...          ...       ...       ...       ...       ...       ...   \n",
       "16099   0.022021  0.000000  0.231765  0.131174  0.000000  0.068234   \n",
       "16100   0.021853  0.009320  0.212488  0.087141  0.000000  0.015771   \n",
       "16101   0.021853  0.009320  0.212488  0.087141  0.000000  0.015771   \n",
       "16102   0.021853  0.009320  0.212488  0.087141  0.000000  0.015771   \n",
       "16103   0.021853  0.009320  0.212488  0.087141  0.000000  0.015771   \n",
       "\n",
       "              clusters  \n",
       "0      Immature Neuron  \n",
       "1      Immature Neuron  \n",
       "2      Immature Neuron  \n",
       "3      Immature Neuron  \n",
       "4      Immature Neuron  \n",
       "...                ...  \n",
       "16099      Radial Glia  \n",
       "16100      Radial Glia  \n",
       "16101      Radial Glia  \n",
       "16102      Radial Glia  \n",
       "16103      Radial Glia  \n",
       "\n",
       "[32147 rows x 2001 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(2024)\n",
    "list_df = []\n",
    "for i in ['Immature Neuron','Neuroblast','Neuron','Radial Glia']:\n",
    "    surface_cells = np.where(latent_adata.obs.clusters.isin([i]))[0]\n",
    "    #surface_cells = surface_cells[np.random.choice(len(surface_cells), size=100, replace=False)]\n",
    "    xhat_surface = ltv.tl.cell_trajectories(z_traj[surface_cells], times[surface_cells], latent_adata, adata, surface_cells, 0.25)\n",
    "    surface_df = pd.DataFrame(xhat_surface, columns=adata.var.index.values)\n",
    "\n",
    "    surface_df['clusters'] = i\n",
    "    list_df.append(surface_df)\n",
    "df = pd.concat(list_df)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(2024)\n",
    "list_degs = []\n",
    "for i in ['Immature Neuron','Neuroblast','Neuron','Radial Glia']:\n",
    "    ery_de = ltv.tl.de_genes(adata, df, i, celltype_key='clusters', mode='greater')\n",
    "    ery_de['clusters'] = i\n",
    "    ery_de = ery_de[ery_de[\"pval\"]<0.05]\n",
    "    list_degs.append(ery_de)\n",
    "degs_all = pd.concat(list_degs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "degs_all.to_csv(\"/home/liyr/zxc/top_like_genes/res/LatentVelo_all_new_0.25.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LatentVelo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
